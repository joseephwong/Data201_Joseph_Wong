{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89ff64c-fd19-406a-9ed2-3cdf13d3b113",
   "metadata": {},
   "source": [
    "## Intermediate Data Science\n",
    "\n",
    "#### University of Redlands - DATA 201\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data201.joannabieri.com](https://joannabieri.com/data201_intermediate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f567cff-9b0f-408d-8f06-ded0cf10a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - This list of package imports is getting long\n",
    "# In a professional setting you would only want to \n",
    "#      import what you need!\n",
    "# I had chatGPT break the packages into groups here\n",
    "\n",
    "# ============================================================\n",
    "# Basic packages\n",
    "# ============================================================\n",
    "import os                             # For file and directory operations\n",
    "import numpy as np                    # For numerical computing and arrays\n",
    "import pandas as pd                   # For data manipulation and analysis\n",
    "\n",
    "# ============================================================\n",
    "# Visualization packages\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt        # Static 2D plotting\n",
    "import seaborn as sns                  # Statistical data visualization built on matplotlib\n",
    "\n",
    "# Interactive visualization with Plotly\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'colab'        # Set renderer for interactive output in Colab or notebooks\n",
    "\n",
    "# ============================================================\n",
    "# Scikit-learn: Core utilities for model building and evaluation\n",
    "# ============================================================\n",
    "from sklearn.model_selection import train_test_split    # Train/test data splitting\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler  # Feature transformations and scaling\n",
    "from sklearn.metrics import (                            # Model evaluation metrics\n",
    "    mean_squared_error, r2_score, accuracy_score, \n",
    "    precision_score, recall_score, confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Scikit-learn: Linear and polynomial models\n",
    "# ============================================================\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor       # For KNN\n",
    "\n",
    "# ============================================================\n",
    "# Scikit-learn: Synthetic dataset generators\n",
    "# ============================================================\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "# ============================================================\n",
    "# Scikit-learn: Naive Bayes models\n",
    "# ============================================================\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# ============================================================\n",
    "# Text Processing Packages and Code\n",
    "# ============================================================\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer as Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b46b9be-55cf-4672-b069-b66a1f8e7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional Code for SPAM problem\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def process(text):\n",
    "    '''\n",
    "    Preprocess text by first making sure it is lower case.\n",
    "    Then remove punctuation and words that are too common (stopwords)\n",
    "\n",
    "    Stopwords are common words in a language that are usually filtered \n",
    "    out before processing text because they carry little semantic meaning for many tasks\n",
    "    '''\n",
    "    # lowercase it\n",
    "    text = text.lower()\n",
    "    # remove punctuation\n",
    "    text = ''.join([t for t in text if t not in string.punctuation])\n",
    "    # remove stopwords\n",
    "    text = [t for t in text.split() if t not in stopwords.words('english')]\n",
    "    # stemming\n",
    "    st = Stemmer()\n",
    "    text = [st.stem(t) for t in text]\n",
    "    # return token list\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3093a585-a00e-496e-ac70-9fb95b7bb54e",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "# YOUR CHOICE!!!!\n",
    "\n",
    "Do ONE of the following.\n",
    "\n",
    "## Spam Detector\n",
    "\n",
    "Following along with the class notes/video - create a spam detector using the kaggle data:\n",
    "\n",
    "```{python}\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"uciml/sms-spam-collection-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file = path + '/' + os.listdir(path)[0]\n",
    "df = pd.read_csv(file, encoding='latin-1')[['v1', 'v2']]\n",
    "df.columns = ['label', 'message']\n",
    "df.head()\n",
    "\n",
    "```\n",
    "\n",
    "## Titanic Data - Bayes Classification\n",
    "\n",
    "Use a Naive Bayes classifier to predict survival on the Titanic Data. \n",
    "\n",
    "Here is a tutorial that you can follow if you want\n",
    "\n",
    "https://www.kaggle.com/code/dimitreoliveira/naive-bayes-probabilistic-ml-titanic-survival\n",
    "\n",
    "```{ptyhon}\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yasserh/titanic-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "file = path + '/' + os.listdir(path)[0]\n",
    "df = pd.read_csv(file)\n",
    "df\n",
    "```\n",
    "\n",
    "\n",
    "You can start on out[4] since we already loaded the kaggle data above.\n",
    "\n",
    "You can also try to make progress on your own. Here are the main points you should try to cover:\n",
    "\n",
    "1. Preprocessing - renaming categorical values with numbers\n",
    "2. Test train split\n",
    "3. Checking correlation of features\n",
    "4. Checking for Gaussian (Normal Distribution)\n",
    "5. Choosing features based on 3,4\n",
    "6. Training a Gaussian Naive Bayes Classifier\n",
    "7. Testing the model\n",
    "\n",
    "\n",
    "Please write up your conclusions.\n",
    "\n",
    "**Your final notebooks should:**\n",
    "\n",
    "- [ ] Be a completely new notebook.\n",
    "- [ ] **Contain your \"best model(s)\" ALONG WITH a discussion of what other things you tried and why these are your best results.**\n",
    "- [ ] Be reproducible with junk code removed.\n",
    "- [ ] Have lots of language describing what you are doing, especially for questions you are asking or things that you find interesting about the data. Use complete sentences, nice headings, and good markdown formatting: https://www.markdownguide.org/cheat-sheet/\n",
    "- [ ] It should run without errors from start to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42811fd7-1183-42bb-a79d-808ae7f9fde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f570fe8-f2d4-4e3c-8b70-b907668da771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c493bc-6d46-4d25-8a6b-dc25001313ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
