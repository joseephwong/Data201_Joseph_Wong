{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cbe71e7-d49a-4d1b-bbdf-a589295e443c",
   "metadata": {},
   "source": [
    "# HW17\n",
    "\n",
    "### Author: Joseph Wong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ba3b8-3ccf-4038-ba65-6552aa70f2f7",
   "metadata": {},
   "source": [
    "## Import the Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01120e1-27a3-479b-ad90-bc31b223c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic package imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn: Core utilities for model building and evaluation\n",
    "from sklearn.model_selection import train_test_split    # Train/test data splitting\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler  # Feature transformations and scaling\n",
    "from sklearn.metrics import (                            # Model evaluation metrics\n",
    "    mean_squared_error, r2_score, accuracy_score, \n",
    "    precision_score, recall_score, confusion_matrix, \n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Scikit-learn: Linear and polynomial models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor       # For KNN\n",
    "\n",
    "# Scikit-learn: Synthetic dataset generators\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "# Scikit-learn: Naive Bayes models\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "# Scikit-learn: Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "\n",
    "# Text Processing Packages and Code\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer as Stemmer\n",
    "\n",
    "# Scikit-Learn: Datasets\n",
    "from sklearn.datasets import fetch_california_housing, load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9e39c-2821-4793-a2c9-728ca37416bd",
   "metadata": {},
   "source": [
    "## Part 1: Iris Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd72b2ff-23d4-4115-aa5c-468ec0fbcb32",
   "metadata": {},
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ee0c03c-04b4-401d-b5d3-24581c2dd241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>Class Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     Class Num  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "145          2  \n",
       "146          2  \n",
       "147          2  \n",
       "148          2  \n",
       "149          2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X_cls, y_cls = iris.data, iris.target\n",
    "feature_names_cls = iris.feature_names\n",
    "class_names_cls = iris.target_names\n",
    "\n",
    "df_iris = pd.DataFrame(X_cls,columns=feature_names_cls)\n",
    "df_iris['Class Num'] = y_cls\n",
    "print(class_names_cls)\n",
    "df_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5c6fe-c31a-42d0-a6b4-0fc8069d9ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de81092c-4130-40c9-856a-2ab648f62e17",
   "metadata": {},
   "source": [
    "1. Using the Iris data - same data as we saw at the end of lecture:\n",
    "   \n",
    "- Fit a DecisionTreeClassifier to the training data.\n",
    "- Evaluate accuracy on the testing data.\n",
    "- Explore the effect of tree depth.\n",
    "- Visualize the tree (limit depth if needed).\n",
    "- Investigate feature importance:\n",
    "    - Which features are most important for classification?\n",
    "    - Does pruning or limiting depth change feature importance?\n",
    "      \n",
    "Hint:\n",
    "*cls_tree.feature_importances_ gives the importance of each feature after fitting.*\n",
    "\n",
    "Some things to consider:\n",
    "- How  does pruning or limiting tree depth affects train/test error?\n",
    "- How does feature importance changes with pruning or depth constraints.\n",
    "- What are the trade-offs between overfitting and underfitting.\n",
    "- Visualization of tree structure for insight.\n",
    "\n",
    "**Optional:**\n",
    "- For the classification tree, reduce to two features and plot decision boundaries.\n",
    "- For the regression tree, plot predictions for a single feature to see the behavior.\n",
    "\n",
    "Please write up your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3aad00-4653-4ca2-8c46-21c2f53d6aac",
   "metadata": {},
   "source": [
    "## Part 2: California Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7651cee-b278-4a8b-acf0-71d673dcf844",
   "metadata": {},
   "source": [
    "### Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc3984-988d-402e-b32b-1db69fb090e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_reg, y_reg = housing.data, housing.target\n",
    "feature_names_reg = housing.feature_names\n",
    "\n",
    "df_housing = pd.DataFrame(X_reg,columns=feature_names_reg)\n",
    "df_housing['Price'] = y_reg\n",
    "df_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb2201-c0a7-4999-9eb4-7bd12cdfb2d0",
   "metadata": {},
   "source": [
    "2. Using the California Housing data:\n",
    "\n",
    "- Fit a DecisionTreeRegressor to the training data.\n",
    "- Evaluate train and test MSE.\n",
    "- Explore pruning using cost-complexity pruning.\n",
    "- Visualize the tree (limit depth if needed).\n",
    "- Investigate feature importance:\n",
    "    - Which features are most important for splitting?\n",
    "    - How does pruning affect feature importance?\n",
    "\n",
    "Hint:\n",
    "*reg_tree.feature_importances_ gives the importance of each feature after fitting.*\n",
    "\n",
    "Some things to consider:\n",
    "- How  does pruning or limiting tree depth affects train/test error?\n",
    "- How does feature importance changes with pruning or depth constraints.\n",
    "- What are the trade-offs between overfitting and underfitting.\n",
    "- Visualization of tree structure for insight.\n",
    "\n",
    "**Optional:**\n",
    "- For the classification tree, reduce to two features and plot decision boundaries.\n",
    "- For the regression tree, plot predictions for a single feature to see the behavior.\n",
    "\n",
    "Please write up your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200a02f2-8008-4dd9-a39f-214466be46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# hyperparameter tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
